# [\#7806 Issue](https://github.com/ethereum/solidity/issues/7806) `closed`: Tune the sequence of Yul optimizer steps using an evolutionary algorithm or similar
**Labels**: `outsourceable`


#### <img src="https://avatars.githubusercontent.com/u/9073706?v=4" width="50">[chriseth](https://github.com/chriseth) opened issue at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806):

The Yul optimizer steps are designed in a way such that each of them is correct in isolation (as long as some mild preconditions are met, which can all be fulfilled by running certain other steps in the beginning of the optimizer run).

Currently, we have a fixed sequence of steps that are run in a loop (Suite.cpp) that has been created manually. We are sometimes facing issues where the sequence leads to suboptimal results and rearranging the steps yields results that are better in all metrics.

Some optimizer steps produce much better results when certain other steps are run first. In general, the performance of the sequence depends on the local structure, but there are almost no interactions between steps that are far away in the sequence.

Because of that, evolutionary / genetic algorithms could be a prefect fit in order to find a good generic sequence of steps.

The goal would be to have a tool in C++ compiled to a binary in the tools directory that runs on a given set of example programs and outputs code to be used in Suite.cpp to fix the sequence of operations.

A good fitness function would probably be a combination of code size (CodeSize in Metrics.h) and the fact that certain optimizations on certain example inputs are in fact performed. These include an sload that is optimized away, a function that is inlined, etc. It might be that code size alone is already sufficient.

It might be beneficial to find a sequence that then is run in a loop until there are no changes anymore, so that it works equally well on small and large programs.

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-586663377):

Here's an update about where we currently are in the process of implementing this feature.

### Phase A
#### What's been implemented so far
1. #8164 added the command-line application (`yul-phaser`) with the ability to parse command-line options, run a sequence of optimisation steps and print basic information about the population.
2. #8223 was a simple optimisation to make the algorithm not parse the program from scratch every time.
3. #8215 moved some of my changes related to optimiser steps to `OptimiserSuite`.
4. There were a few tiny PRs not related directly to this issue. These don't matter here.
5. #8256 implemented an actual genetic algorithm. It was just a draft PR that I have now refined and resubmitted as a series of 5 smaller PRs:
    - #8324: Random number generator and seeding it
    - #8325: Miscellaneous `Population` tweaks and improvements
    - #8326: Fitness metrics
    - #8327: Random algorithm
    - #8328: GEWEP algorithm

#### How far are we
The above taken together cover nearly everything that was planned for phase A. Also the fact that the CI pipeline is very comprehensive and that docs are required upfront in all PRs means that almost everything I was planning to put off until phase D (getting it to work on non-Linux platforms, class docs, a comprehensive set of tests) is already included.

What's left are phases B and C. In the original plan they were given as much time as A and D and work on them should have already started but from the current perspective I estimate that stuff done in phase A actually covers about 70% of the whole effort. Writing the initial code was harder because I was not familiar with the code base. I had to build a lot of mechanisms for the algorithm from scratch. Creating comprehensive tests was also a bit of a challenge, mainly due the fact that lots of the code is meant to produce random-looking results. The PRs listed above add in total nearly 5k new lines of code (probably more than half in tests) and 120 test cases (100 of these in the last 5 PRs which is why it took me so long to finalize it). 

At this point I consider phase A complete (pending the code review of course). There's still one or two things that were meant to be included in that phase (e.g. restarting from last state after Ctrl+C) but these are small modifications just like the features from phase B so given how unexpectedly bigger phase A turned out to be, I think it's fair to move them to phase B.

Compared to phase A phases B and C should be relatively small:
- Phase B consists of a few relatively small features/optimisations that will require very limited modifications to existing code. This will also make reviews considerably easier.
- Phase C got a lot of time allocated to it mainly due to uncertainty of how hard it will be to experiment and how extensive these experiments should be. Now I know that experimenting will be pretty straightforward thanks to the modular structure and basic building blocks I have prepared in phase A. As to the extent of these experiments - that's easy to scale up on down depending on how good the current algorithm turns out to be and how much time I have left.

### Phase B
Starting next week I'm going to start implementing the features from phase B. @chriseth, you wanted to have the option to modify the tasks after phase A so below I'm listing all the relevant tasks that could be included: stuff that was on the original list, the few things moved from phase A and also a few extra improvements and possible changes that were not planned but came up in the PRs. It's more or less in the order of importance. Please let me know if you would to add, remove or reprioritise anything. We can discuss it further on Gitter if you want more info about anything.

1. Ability to save/load algorithm state (so that one can resume execution after Ctrl+C).
2. Taking multiple Yul programs as input.
3. Should `StackCompressor` and/or `ConstantOptimiser` be available as steps or at least used when computing fitness?
4. Printing a list of steps as input for `OptimiserSuite::runSequence()` in a form that can be easily pasted into `Suite.cpp` (or alternatively filling a file template given on the command line).
5. Command-line options for things that are now hard-coded
    - Options for algorithm parameters (population size, mutation chance, etc.).
    - Option for the number of repeats of the optimisation sequence.
6. Gathering per-round and overall statistics
    - average/min/max fitness
    - best sequence
    - number of rounds
    - execution time
    - number of times each optimization step is included in the best sequence
    - how much each step included in a sequence affected the fitness value
7. Replacing duplicates with random chromosomes at the end of each round to avoid the elite filling up with identical chromosomes and effectively reducing the variety of input to mutations and crossover.
8. Even more command-line options
    1. Option for printing the optimised program after each round in addition to the sequences.
    2. Option to stop after a given number of iterations.
    3. Option controlling output verbosity.
    4. Option to print results and/or log to a file.    
    5. Option to apply the sequence of optimisation steps in the metric variable number of times - until the resulting program stops changing.
9. Change internal representation of `Chromosome` from a vector of strings to a string of step abbreviations.
10. Caching fitness of already evaluated chromosomes to avoid the expensive recalculation if they appear again. We could also cache prefixes.

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-588020849):

I got some early results from my experiments with the phaser. It's still just for a single program (I used `test/libyul/yulOptimizerTests/fullSuite/abi_example1.yul` for now) but the results look promising.

### Comparison with the current optimisation sequence
I was curious how it fares compared to the [sequence of optimisations used currently by `OptimiserSuite`](https://github.com/ethereum/solidity/blob/24d6702986e899a85709e0e81c0628c34ef131b8/libyul/optimiser/Suite.cpp#L94-L287). I prepared a chromosome based on that and added it to the initial population:
``` c++
Chromosome(
	"dhfoDgvulfnTUtnIf"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"xarrscLM" "cCTUtTOntnfDIul" "Lcul" "Vculjj" "eul" "xarulrul" "xarrcL" "gvif" "CTUcarrLsTOtfDncarrIulc"
	"jmuljuljulVcTOculjmul"
)
```

([see mapping between letters and steps](https://github.com/ethereum/solidity/blob/24d6702986e899a85709e0e81c0628c34ef131b8/libyul/optimiser/Suite.cpp#L390-L419))

The only differences are:
- The sequence contains a loop that can repeat a large subset of its steps up to 12 times. The loop stops as soon as the program stops improving in size. I can't easily do that inside a chromosome so I started with the worst case of 12 repetitions. This gave me a chromosome with 962 steps (shown above).
- Phaser does not run the `StackCompressor` yet.
- All the chromosomes implicitly start with `FunctionHoister`, `FunctionGrouper` and `ForLoopInitRewriter`. I did not remove them from the chromosome so these are extra steps compared to the original.

The size of the code produced by that sequence is 209 (as reported by `CodeSize::codeSizeIncludingFunctions()`). I kept the phaser running for over 5 hours and in the end it managed to improve the size to 162 and reduce the number of steps from 962 to 29 (97% decrease). Here are some numbers from that run:
```
round: 187,  runtime: 2:00h?, fitness: 164, chromosome length: 522
round: 334,  runtime: 3:00h,  fitness: 164, chromosome length: 372
round: 715,  runtime: 4:00h,  fitness: 162, chromosome length: 132
round: 931,  runtime: 4:30h,  fitness: 162, chromosome length: 90
round: 1830, runtime: 5:00h,  fitness: 162, chromosome length: 35
round: 2450, runtime: 5:30h,  fitness: 162, chromosome length: 29
round: 2609, runtime: 5:40h,  fitness: 162, chromosome length: 29
```

I unfortunately only started tracking it after it's been running for a while so the initial runtimes are not reliable. I know that fitness went down to 162 somewhere around the round 530.

The top half of the final population was:
```
Fitness: 162, optimisations: CfxCIiOglTiscTrvtuaxiciCcUMcl
Fitness: 162, optimisations: CfxCIiOglmiscTrvtuaxiciCcUMcl
Fitness: 162, optimisations: ClfxCIiOgTiscTrvtuaxiciCcUMcl
Fitness: 162, optimisations: CCfxCIiOglTisaTrvtuaxiciCcUMcl
Fitness: 162, optimisations: CCfxCIiOglTiscTrvtuaxiciCcUMcl
Fitness: 162, optimisations: CCfxCIiOglmisaTrvtuaxiciCcUMcl
Fitness: 162, optimisations: CCfxCIiOglmiscTrvtuaxiciCcUMcl
Fitness: 162, optimisations: CCfxCIiOguTisaTrvtuaxiciCcUMcl
Fitness: 162, optimisations: CCfxCIiOguTiscTrvtuaxiciCcUMcl
Fitness: 162, optimisations: CCfxCIiOgumisaTrvtuaxiciCcUMcl
```

#### Observations
- For chromosomes that long it's reeeeeallly slow. I did not measure but feels like at least 30 seconds per round. It'll be significantly worse if there are several programs, especially if they're big. I'm pretty sure that 99% of the time is spent in the optimiser. The fact that the rounds get much quicker as chromosome length decreases seems to confirm that.
- The fitness converges pretty quickly (in terms of number of rounds, not necessarily wall clock time though).
- After getting to a good fitness it's still able to improve the sequence by removing superfluous steps. And the improvement is considerable. Should decrease the optimisation times by a lot. I wonder if it'll hold when I run it on a bigger set of programs.
- I my earlier test runs I remember that the lowest fitness I managed to get for this program was about 170. And that was in a much larger number of rounds than it took the `OptimiserSuite`'s sequence to go below 170. So the current sequence might not be the best fit for this particular input program but it was very easy to evolve it into a better one.

### Caching
While the program was running I spent some time optimizing it:
- I tried caching the optimized program for every chromosome prefix. This unfortunately eats too much memory. With a population of 20 1000-step chromosomes the cache can grow by up to 20000 programs per round. Even with a high ratio of cache hits to misses this is too much and crashes after several rounds on my system with 20 GB RAM.
- I tried caching only prefixes that got at least 2 hits. Still too many programs.
- Then I tried removing cache entries older than 1 round. This gave me acceptable results. Still requires a lot of memory but at least it fits in my RAM and after a few rounds memory usage stops growing and actually starts decreasing (because chromosomes are getting shorter).

With this caching method it took me only about 25 minutes to get to round 253. Could probably be faster but I started it while the original one was still running and kept them running in parallel. At that point I got about 4.7 million optimisation steps applied, of which 3.6 million came from cache and 1.1 million were actually computed. This gives us about 3.3:1 hit/miss ratio. There were about 10000 programs in the cache at that point.

In the initial rounds the ratio was as high as 4.5:1 and cache usage was at the level of 20000 programs.

This improved program was running with a different seed (2 rather than 1) and in an hour went through as many rounds as the one without cache in 5.5 hours. It got the chromosome down to 23 steps (`eamxfijlcTgisvtxMciCcUl`). Fitness is still 162 though.

EDIT: 23 steps is probably as low as it gets. In the next 30 minutes the best chromosome did not change at all.

#### <img src="https://avatars.githubusercontent.com/u/9073706?v=4" width="50">[chriseth](https://github.com/chriseth) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-588102947):

Concerning Phase B:
 - multiple programs is the highest priority I would say
 - StackCompressor and ConstantOptimizer can be completely ignored I would say
 - printing a list of steps for suite.cpp: Maybe it would be better to modify Suite.cpp to take a string of abbreviated step names instead. We could think about how to introduce loops. Maybe "abc(def)gh" could mean that "def" can be repeated, as long as there is improvement.

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-588355044):

Here are the optimised programs you requested:
- [abi_example1-CfxCIiOglTiscTrvtuaxiciCcUMcl.yul](https://github.com/ethereum/solidity/files/4226325/abi_example1-CfxCIiOglTiscTrvtuaxiciCcUMcl.yul.txt)
- [abi_example1-eamxfijlcTgisvtxMciCcUl.yul](https://github.com/ethereum/solidity/files/4226326/abi_example1-eamxfijlcTgisvtxMciCcUl.yul.txt)

Today I let the phaser run for several hours **without** having the sequence from `OptimiserSuite` in the initial population to see if the results will be as good. Unfortunately after 117607 rounds it found a 11-step chromosome (`exMaicisfcl`) but managed to get fitness down only to 173. Here's the result: [abi_example1-exMaicisfcl.yul](https://github.com/ethereum/solidity/files/4226327/abi_example1-exMaicisfcl.yul.txt). This indicates that this algorithm is prone to getting stuck at a local minimum. I'll see in phase C if I can improve it by tweaking the parameters. Maybe it should be a bit more eager to try longer chromosomes when the original one is so short that it's unlikely to improve the fitness. I could add a mutation that simply doubles the current sequence with some probability.

> printing a list of steps for suite.cpp: Maybe it would be better to modify Suite.cpp to take a string of abbreviated step names instead.

I thought about doing it at some point just as an extra functionality but using as a way to avoid having to generate code for `Suite.cpp` is a great idea. With it being just a string of letters it will also be easy to make it a command-line or config file parameter later. I'll add a method that accepts sequences like that and submit a PR.

Should I also replace the current list of steps with an abbreviation string? On one hand I think that the full step names are more readable and they're better if you're creating this sequence by hand. On the other, it's going to be replaced by a generated sequence at some point anyway...

Another thing: chromosome strings implicitly assume the three initial steps that guarantee that we can execute all the others. Should the new method also apply those steps? It's good if you want it to do complete optimisation but not so good if you just want to use it inside `run()` like the current `runSequence()`. Maybe it will be best to have both.

> We could think about how to introduce loops. Maybe "abc(def)gh" could mean that "def" can be repeated, as long as there is improvement.

It would definitely be useful in `OptimiserSuite`. We'll need it if we want to replace the current `runSequence()` calls in `run()` with a single string of abbreviations. Otherwise we'll need three separate strings - which is fine inside `run()` but not necessarily if you later want to be able to pass a single sequence in a parameter.

On the other hand I'm not sure if it makes sense for the genetic algorithm to support this extra syntax in chromosomes. It makes crossover a bit more tricky (you have to make sure that parentheses get closed in each half and it's a bit arbitrary where to close them). It has to be taken into account in mutations to prevent creation of chromosomes with unbalanced parentheses. And if we wanted to support nesting it would get even more complicated.

The one advantage I see is that the algorithm would keep the sequence the same in each loop iteration, making the end result potentially easier for a human to analyze. On the other hand this could also be an unnecessary constraint preventing the algorithm from tweaking only some iterations but not others.

I'll add it in `OptimiserSuite` but I'd prefer to leave adding it to chromosomes until phase E if at that point we still think it's a useful extension.

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-589652439):

I have the results from letting it run overnight with a modified `CodeSize` metric (+1 for blocks, variable declarations, assignments and expression statements):

```
---------- ROUND 15680 ----------
Fitness: 269, optimisations: IaficTrxuivjVsexmuOisgitafruxcujjVcu
Fitness: 269, optimisations: IaficTrxuivjVsexmuOisgitafxurcujjVcu
Fitness: 269, optimisations: IafvicTrxuijVsexmuOisgitafruxcujjVcu
Fitness: 269, optimisations: IafvicTrxuijVsexmuOisgitafxurcujjVcu
Fitness: 269, optimisations: aIficTrxuivjVsexmuOisgitafruxcujjVcu
Fitness: 269, optimisations: aIficTrxuivjVsexmuOisgitafxurcujjVcu
Fitness: 269, optimisations: aIfvicTrxuijVsexmuOisgitafruxcujjVcu
Fitness: 269, optimisations: aIfvicTrxuijVsexmuOisgitafxurcujjVcu
Fitness: 269, optimisations: faIicTrxuivjVsexmuOisgitafruxcujjVcu
Fitness: 269, optimisations: faIicTrxuivjVsexmuOisgitafxurcujjVcu

Cache size:    334951 instructions
Cache hits:    21087733
Cache misses:  5481969
Cache entries: 572
```

Here's the code produced by the top chromosome: [abi_example1-IaficTrxuivjVsexmuOisgitafruxcujjVcu.yul](https://github.com/ethereum/solidity/files/4236232/abi_example1-IaficTrxuivjVsexmuOisgitafruxcujjVcu.yul.txt). It's now smaller than the input (5kB vs 14 kB).

AST composition:
```
YulIdentifier: 287
YulLiteral: 33
YulFunctionCall: 107
YulFunctionDefinition: 5
YulIf: 11
YulBreak: 0
YulContinue: 0
YulLeave: 0
YulForLoop: 5
YulSwitch: 0
YulBlock: 32
YulExpressionStatement: 22
YulAssignment: 26
YulVariableDeclaration: 39
```

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-596457654):

The remaining PRs for the phaser are (in this order):
1. _[yul-phaser] GEWEP algorithm_ #8328
2. _[yul-phaser] Refactoring in main_ #8421
3. _[yul-phaser] Error handling_ #8422
4. _[yul-phaser] Population and algorithm options_ #8423
5. _[yul-phaser] Multi-program support_ #8449 
6. _[yul-phaser] Program cache_ #8451
7. _[yul-phaser] More output_ #8452
8. _Configurable CodeSize metric_ #8453

They're all on top of each other and should be reviewed in that order.

There's also one more that's directly on `develop` but is still marked as "draft" because it needs some discussion: _OptimiserSuite::runSequence() overload for step abbreviations_ #8424.

That's it for phases A, B and D. As for phase C - I haven't finished all experiments yet but I'm nearly done and I'll provide a report with my findings and a final PR that implements them early this week.

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-597384050):

Today I gathered some real-life input for the final run of my experiments. 

While doing it I also got some interesting observations. Here are fitness values for the current optimisation steps from `Suite.cpp` (this is relative fitness, i.e. size of the optimized program compared to the unoptimized one):

| Fitness | File                         |
|---------|------------------------------|
| 10.5%   | `fullSuite/abi2.yul`         |
| 43.8%   | `fullSuite/abi_example1.yul` |
| 104.7%   | `fullSuite/aztec.yul`        |

That's 0.53 on average which seems pretty good. Unfortunately real files are much less squishy. They are much closer to `aztec.yul` than to `abi2.yul`. Here's how the current sequence fares on the input I have gathered:

| Fitness | File                                                  | Source repository                                                                       | Original .sol file                                                                                                                                                              |
|---------|-------------------------------------------------------|-----------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 107.1%   | `AztecProtocol-AZTEC-Swap.yul`                        | [AztecProtocol/AZTEC](https://github.com/AztecProtocol/AZTEC)                           | [Swap.sol](https://raw.githubusercontent.com/AztecProtocol/AZTEC/7eed9ba3f59b7b8641fcc97c77f03dcdeac37151/packages/protocol/contracts/ACE/validators/swap/Swap.sol)             |
| 104.2%   | `GNSPS-solidity-bytes-utils-AssertBytes.yul`          | [GNSPS/solidity-bytes-utils](https://github.com/GNSPS/solidity-bytes-utils)             | [AssertBytes.sol](https://raw.githubusercontent.com/GNSPS/solidity-bytes-utils/b1b22d1e9c4de64defb811f4c65a391630f220d7/contracts/AssertBytes.sol)                              |
| 95.2%   | `GNSPS-solidity-bytes-utils-BytesLib.yul`             | [GNSPS/solidity-bytes-utils](https://github.com/GNSPS/solidity-bytes-utils)             | [BytesLib.sol](https://raw.githubusercontent.com/GNSPS/solidity-bytes-utils/b1b22d1e9c4de64defb811f4c65a391630f220d7/contracts/BytesLib.sol)                                    |
| 92.8%   | `likecoin-likecoin-contracts-LikeChainRelayLogic.yul` | [likecoin/likecoin-contracts](https://github.com/likecoin/likecoin-contracts)           | [LikeChainRelayLogic.sol](https://raw.githubusercontent.com/likecoin/likecoin-contracts/b6bc77f867457f4305050cb96e110a00432f9a2c/likechain-contracts/LikeChainRelayLogic.sol)   |
| 98.6%   | `Loopring-protocols-LzDecompressor.yul`               | [Loopring/protocols](https://github.com/Loopring/protocols)                             | [LzDecompressor.sol](https://raw.githubusercontent.com/Loopring/protocols/925b2a82bb97c1bcc5d52d8d96fb02a91d9afe3c/packages/loopring_v4/contracts/impl/LzDecompressor.sol)      |
| 97.9%   | `nutberry-stack-GatedComputing.yul`                   | [NutBerry/stack](https://github.com/NutBerry/stack)                                     | [GatedComputing.sol](https://raw.githubusercontent.com/NutBerry/stack/0c9a9858547b76b54a2e0b4b0d51bd12aeefac91/contracts/GatedComputing.sol)                                    |
| 96.6%   | `nutberry-stack-LEVM.yul`                             | [NutBerry/stack](https://github.com/NutBerry/stack)                                     | [LEVM.sol](https://raw.githubusercontent.com/NutBerry/stack/0c9a9858547b76b54a2e0b4b0d51bd12aeefac91/contracts/LEVM.sol)                                                        |
| 85.6%   | `pvienhage-ghost-wallet-p256.yul`                     | [pvienhage/ghost-wallet](https://github.com/pvienhage/ghost-wallet)                     | [p256.sol](https://raw.githubusercontent.com/pvienhage/ghost-wallet/7eed3ee3cfb5bc29f6d958ff2900ea7a312a62ca/contracts/p256.sol)                                                |
| 97.6%   | `rynobey-multi-exponent-EcOperations.yul`             | [rynobey/multi-exponent](https://github.com/rynobey/multi-exponent)                     | [EcOperations.sol](https://raw.githubusercontent.com/rynobey/multi-exponent/987c26b4897ef6f7dbd7fa546801be865f4b07ee/contracts/EcOperations.sol)                                |
| 93.2%   | `vaporns-solsha1-SHA1.yul`                            | [vaporns/solsha1](https://github.com/vaporns/solsha1)                                   | [SHA1.sol](https://raw.githubusercontent.com/vaporns/solsha1/440c8d9930b27a01859e072bc8f5ecd7d7e74c2c/contracts/SHA1.sol)                                                       |
| 98.4%   | `zcoinofficial-solidity-BigNumber-BigNumber.yul`      | [zcoinofficial/solidity-BigNumber](https://github.com/zcoinofficial/solidity-BigNumber) | [BigNumber.sol](https://raw.githubusercontent.com/zcoinofficial/solidity-BigNumber/db0d6d298cee2d8974cb6ffa76659d96f3454150/contracts/BigNumber.sol)                            |

This gives us an average of 97%.

The good news is that it takes `yul-phaser` about 15 rounds to beat that result. I have just built this set so I don't have exhaustive results yet but I have already seen the GEWEP algorithm get to 0.927 in one of the runs (`IecsdOiDaxiCfDcrCCoVTMusvvvxrxcsTnujVemsuj`, 41 steps). This confirms that the phaser can improve upon the current sequence. Now the question is just how low can different variations of the algorithms and their parameters get us.

#### <img src="https://avatars.githubusercontent.com/u/9073706?v=4" width="50">[chriseth](https://github.com/chriseth) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-598216152):

We already concluded in the chat that hand-written yul files are probably not a good target, because they are usually already well-optimized. Also note that abi2.yul contains many unused functions, so maybe it is better to first remove the unused functions and use that as input.

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-598229562):

Yeah. I've been rerunning some of my experiments during the night because of that. I initially did them on this set. Yesterday I started using the top 10 biggest files from `viaYul` dir you suggested. Now I'll have results from both and I'll post them side by side. I still think that the set above can give us some insight into how the algorithms perform relative to each other, even if it's not the best input to use in practice.

I'm actually still waiting for some of the new runs to finish and preparing plots and conclusions in the meantime. Each experiment run takes hours of time of a single CPU core to run unfortunately and even that only after I settled for just 500 rounds. Running on 10 files with 100+ step sequences and 50 chromosomes in each round is much slower than my initial tests on one file with 30 step sequences and 20 chromosomes, though a release build speeds things up significantly (4-8 times).

Results on `viaYul` set are not as good. The best I got so far is 51.3% on a 61 step sequence (`eCCDCevaTCxCrIcnTLisCjiCCffCTurjCgceiarmuMrvlsoVcmsujTtOgjfeu`). Still slightly better than `Suite.cpp` with 53.1% but I was expecting lower values.

#### <img src="https://avatars.githubusercontent.com/u/9073706?v=4" width="50">[chriseth](https://github.com/chriseth) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-598243942):

I think 51.3 compared to 53.1 is very significant - the big reductions are probably rather easy to find and it is much harder to find the tiny tweaks.

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-598644491):

## yul-phaser experiment report

### Algorithms and parameters
#### Algorithms
1. **Random algorithm** ([#8327](https://github.com/ethereum/solidity/pull/8327)): a completely random algorithm that in each round creates a new set of chromosomes and discards the old population, except for the top chromosome which is carried over.
2. **GenerationalElitistWithExclusivePools (GEWEP)** ([#8328](https://github.com/ethereum/solidity/pull/8328)): a custom algorithm that preserves top chromosomes in each round and replaces the rest by either mutating or crossing over the ones that were preserved.
3. **Classic genetic algorithm**: a typical genetic algorithm that works in three distinct phases, each resulting in a new, modified population:
    - selection: chromosomes are selected from the population with probability proportional to their fitness. A chromosome can be selected more than once. The new population has the same size as the old one.
    - crossover: first, for each chromosome we decide whether it undergoes crossover or not (according to _crossover chance_ parameter). Then each selected chromosome is randomly paired with one other selected chromosome. Each pair produces a pair of children and gets replaced by it in the population.
    - mutation: we go over each gene in the population and independently decide whether to mutate it or not (according to _mutation chance_ parameter). This is repeated for every mutation type so one gene can undergo mutations of multiple types in a single round.

    My implementation of this algorithm also has the ability to preserve the top chromosomes in each round.

### Mutations
There are three mutation operators available in all algorithms:
- Gene randomisation
- Gene deletion
- Gene addition

The way they're chosen and used depends on the algorithm. For example the random algorithm never mutates anything. Other algorithms have parameters that control the probability of each mutation type and it's possible to set these parameters to zero. GEWEP applies only one type to a given chromosome while the classic algorithm applies them all.

#### Crossover
There are three crossover operators available in all algorithms:
- **1-point crossover**: selects a random location within the shorter of the chromosomes and then swaps the chromosome halves.
- **2-point crossover**: selects two random locations within the shorter of the chromosomes and then swaps the middle part.
- **uniform crossover**: for each gene randomly decides whether to swap it or not.

An algorithm receives the operator a parameter of the experiment.

### Input files
Each experiment was performed on one of two distinct sets of input files:

1. **hand-crafted assembly**: 11 Yul files created by manually extracting and sometimes slightly tweaking the `assembly` blocks from selected Solidity contracts found on github. Their total size is 146 kB. The current optimiser sequence from `Suite.cpp` reduces their average size (according to `CodeSize` metric with non-zero weights) to 97% of the original size.

    | File size | Reduces to | Yul file                                              | Source repository                                                                       | Original .sol file                                                                                                                                                              |
    |-----------|------------|-------------------------------------------------------|-----------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    |     16 kB | 107.1%     | `AztecProtocol-AZTEC-Swap.yul`                        | [AztecProtocol/AZTEC](https://github.com/AztecProtocol/AZTEC)                           | [Swap.sol](https://raw.githubusercontent.com/AztecProtocol/AZTEC/7eed9ba3f59b7b8641fcc97c77f03dcdeac37151/packages/protocol/contracts/ACE/validators/swap/Swap.sol)             |
    |      4 kB | 104.2%     | `GNSPS-solidity-bytes-utils-AssertBytes.yul`          | [GNSPS/solidity-bytes-utils](https://github.com/GNSPS/solidity-bytes-utils)             | [AssertBytes.sol](https://raw.githubusercontent.com/GNSPS/solidity-bytes-utils/b1b22d1e9c4de64defb811f4c65a391630f220d7/contracts/AssertBytes.sol)                              |
    |     17 kB |  95.2%     | `GNSPS-solidity-bytes-utils-BytesLib.yul`             | [GNSPS/solidity-bytes-utils](https://github.com/GNSPS/solidity-bytes-utils)             | [BytesLib.sol](https://raw.githubusercontent.com/GNSPS/solidity-bytes-utils/b1b22d1e9c4de64defb811f4c65a391630f220d7/contracts/BytesLib.sol)                                    |
    |     15 kB |  92.8%     | `likecoin-likecoin-contracts-LikeChainRelayLogic.yul` | [likecoin/likecoin-contracts](https://github.com/likecoin/likecoin-contracts)           | [LikeChainRelayLogic.sol](https://raw.githubusercontent.com/likecoin/likecoin-contracts/b6bc77f867457f4305050cb96e110a00432f9a2c/likechain-contracts/LikeChainRelayLogic.sol)   |
    |      4 kB |  98.6%     | `Loopring-protocols-LzDecompressor.yul`               | [Loopring/protocols](https://github.com/Loopring/protocols)                             | [LzDecompressor.sol](https://raw.githubusercontent.com/Loopring/protocols/925b2a82bb97c1bcc5d52d8d96fb02a91d9afe3c/packages/loopring_v4/contracts/impl/LzDecompressor.sol)      |
    |     11 kB |  97.9%     | `nutberry-stack-GatedComputing.yul`                   | [NutBerry/stack](https://github.com/NutBerry/stack)                                     | [GatedComputing.sol](https://raw.githubusercontent.com/NutBerry/stack/0c9a9858547b76b54a2e0b4b0d51bd12aeefac91/contracts/GatedComputing.sol)                                    |
    |      8 kB |  96.6%     | `nutberry-stack-LEVM.yul`                             | [NutBerry/stack](https://github.com/NutBerry/stack)                                     | [LEVM.sol](https://raw.githubusercontent.com/NutBerry/stack/0c9a9858547b76b54a2e0b4b0d51bd12aeefac91/contracts/LEVM.sol)                                                        |
    |     19 kB |  85.6%     | `pvienhage-ghost-wallet-p256.yul`                     | [pvienhage/ghost-wallet](https://github.com/pvienhage/ghost-wallet)                     | [p256.sol](https://raw.githubusercontent.com/pvienhage/ghost-wallet/7eed3ee3cfb5bc29f6d958ff2900ea7a312a62ca/contracts/p256.sol)                                                |
    |     38 kB |  97.6%     | `rynobey-multi-exponent-EcOperations.yul`             | [rynobey/multi-exponent](https://github.com/rynobey/multi-exponent)                     | [EcOperations.sol](https://raw.githubusercontent.com/rynobey/multi-exponent/987c26b4897ef6f7dbd7fa546801be865f4b07ee/contracts/EcOperations.sol)                                |
    |      6 kB |  93.2%     | `vaporns-solsha1-SHA1.yul`                            | [vaporns/solsha1](https://github.com/vaporns/solsha1)                                   | [SHA1.sol](https://raw.githubusercontent.com/vaporns/solsha1/440c8d9930b27a01859e072bc8f5ecd7d7e74c2c/contracts/SHA1.sol)                                                       |
    |     13 kB |  98.4%     | `zcoinofficial-solidity-BigNumber-BigNumber.yul`      | [zcoinofficial/solidity-BigNumber](https://github.com/zcoinofficial/solidity-BigNumber) | [BigNumber.sol](https://raw.githubusercontent.com/zcoinofficial/solidity-BigNumber/db0d6d298cee2d8974cb6ffa76659d96f3454150/contracts/BigNumber.sol)                            |

1. **semantic tests**: 10 biggest files out of the ones created by running `solc --ir --no-optimize-yul` on Solidity contracts from `solidity/test/libsolidity/semanticTests/viaYul/` directory in the repository. Their total size is 322 kB. The sequence from `Suite.cpp` reduces their average size to 53.8% of the original size.

    | File size | Reduces to | Yul file                                    | Source contract                                                                                                                                                                                      |
    |-----------|------------|---------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
    |     24 kB | 50.8%      | `array_memory_index_access.sol-C.yul`       | [array_memory_index_access.sol](https://github.com/ethereum/solidity/blob/b1e43833c70d7b010de9c1401e12de1d0f6e1d00/test/libsolidity/semanticTests/viaYul/array_memory_index_access.sol)              |
    |     20 kB | 59.1%      | `array_storage_index_access.sol-C.yul`      | [array_storage_index_access.sol](https://github.com/ethereum/solidity/blob/b1e43833c70d7b010de9c1401e12de1d0f6e1d00/test/libsolidity/semanticTests/viaYul/array_storage_index_access.sol)            |
    |     30 kB | 53.8%      | `array_storage_index_zeroed_test.sol-C.yul` | [array_storage_index_zeroed_test.sol](https://github.com/ethereum/solidity/blob/b1e43833c70d7b010de9c1401e12de1d0f6e1d00/test/libsolidity/semanticTests/viaYul/array_storage_index_zeroed_test.sol)  |
    |     23 kB | 53.8%      | `comparison.sol-C.yul`                      | [comparison.sol](https://github.com/ethereum/solidity/blob/b1e43833c70d7b010de9c1401e12de1d0f6e1d00/test/libsolidity/semanticTests/viaYul/comparison.sol)                                            |
    |     68 kB | 42.6%      | `erc20.sol-ERC20.yul`                       | [erc20.sol](https://github.com/ethereum/solidity/blob/b1e43833c70d7b010de9c1401e12de1d0f6e1d00/test/libsolidity/semanticTests/viaYul/erc20.sol)                                                      |
    |     26 kB | 61.8%      | `function_cast.sol-C.yul`                   | [conversion/function_cast.sol](https://github.com/ethereum/solidity/blob/b1e43833c70d7b010de9c1401e12de1d0f6e1d00/test/libsolidity/semanticTests/viaYul/conversion/function_cast.sol)                |
    |     24 kB | 53.9%      | `if.sol-C.yul`                              | [if.sol](https://github.com/ethereum/solidity/blob/b1e43833c70d7b010de9c1401e12de1d0f6e1d00/test/libsolidity/semanticTests/viaYul/if.sol)                                                            |
    |     33 kB | 45.2%      | `local_tuple_assignment.sol-C.yul`          | [local_tuple_assignment.sol](https://github.com/ethereum/solidity/blob/b1e43833c70d7b010de9c1401e12de1d0f6e1d00/test/libsolidity/semanticTests/viaYul/local_tuple_assignment.sol)                    |
    |     41 kB | 55.4%      | `mappings.sol-C.yul`                        | [storage/mappings.sol](https://github.com/ethereum/solidity/blob/b1e43833c70d7b010de9c1401e12de1d0f6e1d00/test/libsolidity/semanticTests/viaYul/storage/mappings.sol)                                |
    |     37 kB | 62.2%      | `unary_operations.sol-C.yul`                | [unary_operations.sol](https://github.com/ethereum/solidity/blob/b1e43833c70d7b010de9c1401e12de1d0f6e1d00/test/libsolidity/semanticTests/viaYul/unary_operations.sol)                                |

In each experiment `yul-phaser` receives the whole set as input. Fitness is computed separately for each program and then averaged to produce the combined fitness of a chromosome. Values are relative to the sizes of unoptimised programs.

### Experiments
Based on previous experiments I selected the most promising parameters for each algorithm as a baseline:

1. Parameters common to all algorithms
    - *population size*: 50
    - *chromosome length*: random, between 5 and 100
    - *duplicate randomisation*: enabled
    - *crossover operator*: uniform, 50% chance of swap for each gene
1. **Random**
    - *elite size*: 1 individual
2. **GEWEP**
    - *elite pool size*: 20% of the population
    - *crossover pool size*: 60% of the population
    - *mutation pool size*: 20% of the population
    - *probability that a mutation is gene randomisation*: 90%
    - *probability that a mutation is gene deletion*: 5%
    - *probability that a mutation is gene addition*: 5%
    - *probability that a gene gets randomised*: 3.3%
    - *probability that a gene gets deleted*: 3.3%
    - *probability that a gene gets added*: 3.3%
3. **Classic**
    - *elite pool size*: 1 individual
    - *crossover chance*: 75%
    - *probability that a gene gets randomised*: 3.3%
    - *probability that a gene gets deleted*: 3.3%
    - *probability that a gene gets added*: 3.3%

#### 1. Baseline
In this experiment I simply ran all the algorithms multiple times with baseline parameters.

##### hand-crafted input
![01a-baseline-round-fitness](https://user-images.githubusercontent.com/137030/76610260-f73fde80-6518-11ea-8a43-d040abe962e6.png)
![01a-baseline-time-fitness](https://user-images.githubusercontent.com/137030/76610264-f7d87500-6518-11ea-8d45-694dd988b574.png)
![01b-baseline-averages-round-fitness](https://user-images.githubusercontent.com/137030/76610266-f8710b80-6518-11ea-8679-7dd99d4e0ec6.png)
![01b-baseline-averages-time-fitness](https://user-images.githubusercontent.com/137030/76610268-f909a200-6518-11ea-95b8-2cd2c4685aa0.png)

Final chromosomes selected in each run of the random algorithm:

| Seed | Length | Fitness | Optimisation steps                                                                                             | Unique steps                   |
|------|--------|---------|----------------------------------------------------------------------------------------------------------------|--------------------------------|
| 1    | 75     | 95.0%   | `dMajMjvtjjDjeaggsmvdiTlfMMOxoOdihsoDijilrVjTutgVLiUtTgcVMmrIomOuILMjmuOlUji`                                  | `.DILMOTUVacdefghijlm.orstuvx`
| 2    | 93     | 94.0%   | `cfsjVtTuLrutngxVxtmiDtaUcrlTuulgnfVoTIUxdoirsLVUlVeIimMchrDggOlurdclgMjhnIgOUrTmurMfmgjvUfOUs`                | `.DILMOTUVacdefghijlmnorstuvx`
| 3    | 99     | 94.8%   | `UIjntneVCxfsglcUcvjteceUacrlfjCefTxfjxofchvmjIoMjUsdnohhnlrOmdClxuljhUfleMlVUrLglThijTODmUvsDDuujfi`          | `CDILMOTUVacdefghijlmnorstuvx`
| 4    | 99     | 94.5%   | `gTVnfClhnfncITgcraonvcgMtjmCumgUmdgdxVeiOlvdOvarhngxiUaxVhOdjTTDODDdUMrTthUVrrnhrjsvcjVuDmletlOThul`          | `CDI.MOTUVacdefghijlmnorstuvx`
| 5    | 96     | 93.9%   | `IgLaojTLIceliVtMvreraDCjrmosvvlLVLOmxOunctgujMItVheLuInVoMjcMxnjxLilsUjouLmxuOTmOnfjrnMsTsummOjt`             | `CDILMOTUVac.efghijlmnorstuvx`

Final chromosomes selected in each run of the GEWEP algorithm:

| Seed | Length | Fitness | Optimisation steps                                                                                             | Unique steps                   |
|------|--------|---------|----------------------------------------------------------------------------------------------------------------|--------------------------------|
| 1    | 48     | 92.6%   | `aijTCCeuCxcMcrIisUfDxarIacsMMujLVTjMmuCTvvjOscru`                                                             | `CDILMOTUVac.ef..ij.m..rs.uvx`
| 2    | 36     | 92.7%   | `eDDiDxarcsimLCMxCfcrTmuVCLjUmersujcu`                                                                         | `CD.LM.TUVac.ef..ij.m..rs.u.x`
| 3    | 24     | 94.2%   | `xaifcjurDMDusMVjLceTDmsu`                                                                                     | `.D.LM.T.Vac.ef..ij.m..rs.u.x`
| 4    | 28     | 92.5%   | `avjxcifraLjumDrMTuVessxcTujjj`                                                                                | `.D.LM.T.Vac.ef..ij.m..rs.uvx`
| 5    | 32     | 92.9%   | `sCxDvDcicjCmLMfajumrsrTjuVscmeuD`                                                                             | `CD.LM.T.Vac.ef..ij.m..rs.uvx`


Final chromosomes selected in each run of the classic algorithm:

| Seed | Length | Fitness | Optimisation steps                                                                                             | Unique steps                   |
|------|--------|---------|----------------------------------------------------------------------------------------------------------------|--------------------------------|
| 1    | 72     | 93.8%   | `OeLiCDTDljsjliMLjadxhhcjejrTtvjsvmvjooogVtOijvudlmlfutOjcsutrtLjvCtlrTet`                                     | `CD.LMOT.Vacdefghijlm orstuvx`
| 2    | 79     | 93.1%   | `iTfcgexlcsTadixVavtsurLhsoTVrLiMcChTntvusLlmUDVMohjcjfmtsTotOrmohtjreTttnUoliLu`                              | `CD.LMOTUVacdefghijlmnorstuvx`
| 3    | 34     | 94.3%   | `iuioMDMfLaorVsTUlrsecMTfurleVnmumm`                                                                           | `.D.LM.TUVac.ef..i.lmnors.u..`
| 4    | 108    | 93.2%   | `dVIITteUCOTsiOIflOOdfMcmCuUggUndVDtiaMUOjcTIsiuvTDirsVUtMhoxUnTUunfsIMslMcLhoOuLtUCuUjugsOmrOMejOunfOOlUlOsl` | `CDILMOTUVacdefghijlmnorstuvx`
| 5    | 59     | 92.9%   | `IviMTDOdtaLaLIvfgOiCufrnIDLhVujeOVLrdIlsxnVxcMOIjTddMmOduhj`                                                  | `CDILMOT.Vacdefghijlmn.rstuvx`

Observations:
- There's a large variance between results of different runs of the same algorithm. In its best runs the random search even managed to find sequences with better fitness than the genetic algorithms in their worst runs.
- On average the genetic algorithms are clearly better. GEWEP finds the best fitness values and converges to them the fastest.
- Relatively good performance of the random algorithm indicates that good-enough variants of optimisation strings must be common for this input and it's easy to get lucky.
- The random algorithm converges in big jumps rather than small, incremental steps. Genetic algorithms, on the other hand, slowly improve their chromosomes. This shows in how they're often able to find a shorter chromosome that has the same fitness. GEWEP is better at this than the classic algorithm - the length decreases faster and the final result is shorter.
- Chromosomes found by the random search and the classic algorithm have all or nearly all optimisation steps in them. Chromosomes from GEWEP are usually missing the same steps:
    - `g`: `FunctionGrouper`
    - `h`: `FunctionHoister`
    - `o`: `ForLoopInitRewriter`
    - `d`: `VarDeclInitializer`
    - `l`: `CircularReferencesPruner`
    - `n`: `ControlFlowSimplifier`
    - `t`: `StructuralSimplifier`
    - `I`: `ForLoopConditionIntoBody`
    - `O`: `ForLoopConditionOutOfBody`

    The first three are automatically applied by the phaser to every program. The rest probably optimise things that are not very common in the input files from this set.

##### `viaYul` input
![01a-baseline-round-fitness](https://user-images.githubusercontent.com/137030/76610486-46860f00-6519-11ea-9d35-16a3e558159f.png)
![01a-baseline-time-fitness](https://user-images.githubusercontent.com/137030/76610490-471ea580-6519-11ea-9d0b-70d7ce63b6cb.png)
![01b-baseline-averages-round-fitness](https://user-images.githubusercontent.com/137030/76610493-47b73c00-6519-11ea-8fb1-a67ee89f676b.png)
![01b-baseline-averages-time-fitness](https://user-images.githubusercontent.com/137030/76610494-47b73c00-6519-11ea-9e42-83231c35dfb8.png)

I ran the random algorithm only once for this input set since it's not essential for the comparison.

Final chromosomes selected in each run of the random algorithm:

| Seed | Length | Fitness | Optimisation steps                                                                                                                                        | Unique steps                   |
|------|--------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------|
| 1    | 93     | 55.2%   | `iMegsaxUlCficvOUcmMuifLDmjtvmOMjecIsDfrexTvhCCfMuLslOUrDhsjlmjfOCtMrnTvLUveeDLuTmUfDtgthOLfVr`                                                           | `CDILMOTUVac.efghijlmn.rstuvx`

Final chromosomes selected in each run of the GEWEP algorithm:

| Seed | Length | Fitness | Optimisation steps                                                                                                                                        | Unique steps                   |
|------|--------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------|
| 1    | 61     | 51.3%   | `eCCDCevaTCxCrIcnTLisCjiCCffCTurjCgceiarmuMrvlsoVcmsujTtOgjfeu`                                                                                           | `CDILMOT.Vac.efg.ijlmnorstuvx`
| 2    | 39     | 52.1%   | `CDiesiuxCfcCLrvTtniacTrujDDvDOeMsVmLsuj`                                                                                                                 | `CD.LMOT.Vac.ef..ij.mn.rstuvx`
| 3    | 46     | 51.9%   | `ievLlCifDasCIiDmIutcTxnLrmueVmuOesMjMMVomevDus`                                                                                                          | `CDILMOT.Vac.ef..ijlmnorstuvx`
| 4    | 37     | 51.9%   | `xiDslifaCrDLLujnxmIuVsetcuTjersOvjmnu`                                                                                                                   | `CDIL.OT.Vac.ef..ijlmn.rstuvx`
| 5    | 45     | 52.1%   | `CCevrefsilDMgarniicxLITrCIussUTeujvteOuVjimfu`                                                                                                           | `CDILMOTUVac.efg.ijlmn.rstuvx`

Final chromosomes selected in each run of the Classic algorithm:

| Seed | Length | Fitness | Optimisation steps                                                                                                                                        | Unique steps                   |
|------|--------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------|
| 1    | 148    | 52.0%   | `sveIiunniaxgfVdVVDoMgalaLftuvjljsfgslgmhedhuTlugthjTMsldcnIgOlxeleuIsndhjvfnmomjOVxgjiIrUxmLIuovmeoaDMddsUsfeLrcUTuTrusjgTtViecjcimMOTdfDuutrmumDDTD`    | `.DILMOTUVacdefghijlmnorstuvx`
| 2    | 151    | 51.9%   | `imIxOhfVfrTmIldnLVtOsilchuTcVDxemomdmsaCtDTLrfcaxLjhUgceuDjClumuucVOnufCMvfmrtVsVtTsnleOrVexmeTvTicrcMsjtrtlOessCLCdgTvmjfTDeIunLgUuUDUnmfMfjmVCeOuevrO` | `CDILMOTUVacdefghijlmnorstuvx`
| 3    | 123    | 51.9%   | `VhirsMxgiDDtDMIgviDaarVfenrcVenTngOxvOuMvLrIVMgMsreminvaUOetrdTtLvedhmujesiexvTghUouDfvosucLTOOuufVujuOifsmIODTifmurfeOhcDV`                             | `.DILMOTUVacdefghij.mnorstuvx`
| 4    | 116    | 52.2%   | `DhxdfguiDcUfDTmuguOnsUeVddfrVMsLgCifigcnOTfgTcDadaajrvxfuvsttnesshrmnvaDTLucgmUcTshDmhujfvetTgsuVuVoLOfxjevmulLCrTLO`                                    | `CD.LMOTUVacdefghijlmnorstuvx`
| 5    |

Observations:
- Here the variance is much smaller. Final fitness and convergence rate are pretty consistent between runs, with few outliers.
- Random search gives the worst results. The sample is small though (only one run).
- GEWEP converges faster than the Classic algorithm but both get very similar results.
- Both genetic algorithms produce final chromosomes with fitness better than 53.8% (fitness of the sequence from `Suite.cpp`).
- GEWEP again produces much shorter final chromosomes than the classic algorithm.
    - Surprisingly, the chromosomes from the classic algorithm got even longer than the ones in the initial population. A closer look at the top chromosome in each round shows that the algorithm selects progressively longer chromosomes for about 150-300 rounds (depending on experiment run) and then finally settles, starting to very slowly whittle them down. In 500 rounds it does not make significant progress on that though.
- The classic algorithm took significantly more time than GEWEP to execute 500 rounds. It ran for 2-3 times longer than GEWEP. This is due to it working with much longer chromosomes.
- Again there are some steps consistently missing from GEWEP's chromosomes (in addition to the expected `f`, `g` and `o`):
    - `d`: `VarDeclInitializer`
    - `U`: `ConditionalUnsimplifier`

#### 2. Long chromosomes

##### hand-crafted input
![02-long-chromosomes-round-fitness](https://user-images.githubusercontent.com/137030/76610269-f909a200-6518-11ea-91f0-7ae7a9616ab3.png)
![02-long-chromosomes-time-fitness](https://user-images.githubusercontent.com/137030/76610271-f9a23880-6518-11ea-9aae-86acce0df4cb.png)

Observations:
- Both genetic algorithms perform better than baseline average when the initial population contains only long chromosomes.
- Both 200-step versions have better final fitness and convergence speed than 100-step ones. Especially in GEWEP the final fitness is reached very early, which more than compensates for each round taking more time.
- In the span of 500 rounds GEWEP with 100-step chromosomes ends with a much shorter sequence than 200-step one. The 200-step one shows a clear downward trend though so a shorter sequence could still be found if we allowed it to execute more rounds.
- Both algorithms with both 100- and 200-step sequences get to the final fitness level pretty fast. After round 300 the only thing that changes is the decreasing chromosome length.
- The classic algorithm converges a little slower and gives worse final fitness than GEWEP. It also takes 3-4 times more time to execute 500 rounds.
    - Unfortunately the timing does not seem reliable enough to draw firm conclusions. I used the `clock()` function which should report only CPU cycles used by the process but I noticed that during a high CPU load the reported times were often closer to wall-clock time than to actual CPU usage of the process per unit of time. In future experiments it would be better to replace it with an alternative timer, e.g. from Boost.
- Using longer chromosomes reduces the gap in final fitness and convergence between GEWEP and the classic algorithm.

#### 3. Short chromosomes

##### hand-crafted input
![03a-short-chromosomes-round-fitness](https://user-images.githubusercontent.com/137030/76610273-fa3acf00-6518-11ea-8d61-19af6536e784.png)
![03a-short-chromosomes-time-fitness](https://user-images.githubusercontent.com/137030/76610277-fa3acf00-6518-11ea-8394-e7cd842a48ed.png)
![03b-short-chromosomes-2000-rounds-round-fitness](https://user-images.githubusercontent.com/137030/76610279-fad36580-6518-11ea-98cd-76a3daba7e77.png)
![03b-short-chromosomes-2000-rounds-time-fitness](https://user-images.githubusercontent.com/137030/76610282-fb6bfc00-6518-11ea-8711-22b81f1d40af.png)

Observations:
- Short initial chromosomes do not usually lead to better final fitness or faster convergence.
- In case of GEWEP the final fitness is much worse than the baseline average. It converges very quickly but then gets stuck with the same short chromosome that does not improve. The second pair of plots shows that this does not change even if we let it run longer (2000 rounds).
- The classic algorithm gets close to the baseline after enough time but still not significantly better.

##### `viaYul` input
![03-short-chromosomes-round-fitness](https://user-images.githubusercontent.com/137030/76610496-484fd280-6519-11ea-8949-77fe0d72cec0.png)
![03-short-chromosomes-time-fitness](https://user-images.githubusercontent.com/137030/76610498-484fd280-6519-11ea-9477-98c496b95e67.png)

Observations:
- The situation is similar as for hand-crafted input.

#### 4. Big population

##### hand-crafted input
![04-big-population-round-fitness](https://user-images.githubusercontent.com/137030/76610285-fb6bfc00-6518-11ea-9647-b47261e52ae3.png)
![04-big-population-time-fitness](https://user-images.githubusercontent.com/137030/76610286-fc049280-6518-11ea-9c10-6d46b70581fb.png)

The violet lines are the results of GEWEP runs where I mistakenly used defaults instead of baseline parameters. Since I don't have enough proper data for this experiment I decided to include it anyway.

Observations:
- There seems to be some improvement over the baseline for GEWEP. The classic algorithm gets better final fitness but converges slower and more erratically. I only have results are for a single run of each though so it's hard to draw a conclusion that the new parameters are better. Especially given that the results for GEWEP with defaults have big variance.
- The 50 chromosomes I put in the baseline is already an increase from the 20 I used initially. I changed it to a greater number because some rudimentary experiments indicated that higher was better. It's possible that 50 is already good enough.
    - Genetic algorithms typically have a specific, optimal population size that depends on the type of the algorithm and its parameters. Population size in general is one of the most important variables for such an algorithm. Here it doesn't show much difference but it might still be a good idea to experiment with it a bit more.

#### 5. Duplicate randomisation

##### hand-crafted input
![05a-duplicate-randomisation-gewep-round-fitness](https://user-images.githubusercontent.com/137030/76610288-fc9d2900-6518-11ea-884a-ff03d8043109.png)
![05a-duplicate-randomisation-gewep-time-fitness](https://user-images.githubusercontent.com/137030/76610290-fc9d2900-6518-11ea-96b8-eb34b3791178.png)
![05b-duplicate-randomisation-classic-round-fitness](https://user-images.githubusercontent.com/137030/76610291-fd35bf80-6518-11ea-9be9-cc9c8d45cf6d.png)
![05b-duplicate-randomisation-classic-time-fitness](https://user-images.githubusercontent.com/137030/76610293-fd35bf80-6518-11ea-8a32-36194cd243b7.png)

Here the lines with duplicate randomisation are simply the baseline curves. I included them in addition to the average to be able to spot any potential correlation with the results without randomisation for the same seed.

Observations:
- In the classic algorithm runs with and without randomisation give very similar results. Neither seems better.
- In case of GEWEP there's some similarity in the early rounds but then the two version diverge. Here also neither version is consistently better.

##### `viaYul` input
![05a-duplicate-randomisation-gewep-round-fitness](https://user-images.githubusercontent.com/137030/76610503-48e86900-6519-11ea-8c98-6b564c4b28d7.png)
![05a-duplicate-randomisation-gewep-time-fitness](https://user-images.githubusercontent.com/137030/76610505-48e86900-6519-11ea-9e1b-17c07225ea23.png)
![05b-duplicate-randomisation-classic-round-fitness](https://user-images.githubusercontent.com/137030/76610507-4980ff80-6519-11ea-8927-21391d08400d.png)
![05b-duplicate-randomisation-classic-time-fitness](https://user-images.githubusercontent.com/137030/76610508-4a199600-6519-11ea-939c-668fcfc8f262.png)

Observations:
- For this input all the runs produced very similar results and duplicate randomisation did not seem to have affected that. The results aren't consistently better or worse. They're just slightly different.

#### 6. Crossover operators

##### hand-crafted input
![06a-single-point-crossover-round-fitness](https://user-images.githubusercontent.com/137030/76610295-fdce5600-6518-11ea-95a6-151885a8036e.png)
![06a-single-point-crossover-time-fitness](https://user-images.githubusercontent.com/137030/76610297-fe66ec80-6518-11ea-8e6c-45206d8817c9.png)
![06b-two-point-crossover-round-fitness](https://user-images.githubusercontent.com/137030/76610298-fe66ec80-6518-11ea-82a3-a50e00ba2336.png)
![06b-two-point-crossover-time-fitness](https://user-images.githubusercontent.com/137030/76610300-feff8300-6518-11ea-93bc-c85c18313fe9.png)

Observations:
- Results for 1- and 2-point crossover are oddly similar.
- For the classic algorithm the results are sometimes slightly better but more often worse than baseline average (which uses uniform crossover).
- For GEWEP both operators eventually end up with slightly better results than uniform crossover on average even though convergence is slower in one case.

##### `viaYul` input
![06a-single-point-crossover-round-fitness](https://user-images.githubusercontent.com/137030/76610510-4a199600-6519-11ea-81d6-d3495c90211a.png)
![06a-single-point-crossover-time-fitness](https://user-images.githubusercontent.com/137030/76610512-4ab22c80-6519-11ea-89c6-a5e80a2e5346.png)
![06b-two-point-crossover-round-fitness](https://user-images.githubusercontent.com/137030/76610513-4ab22c80-6519-11ea-8d93-d60c893867ec.png)
![06b-two-point-crossover-time-fitness](https://user-images.githubusercontent.com/137030/76610515-4b4ac300-6519-11ea-9438-a058162bed47.png)

- Here results from all operators are very close. The differences are not big enough to confidently say that one of the operators is better.
- 1-point crossover ends up giving slightly worse final fitness than uniform crossover while it's the opposite with 2-point crossover.

#### 7. Elite size
![07-elite-round-fitness](https://user-images.githubusercontent.com/137030/76610301-feff8300-6518-11ea-8b63-2e230b97ec77.png)
![07-elite-time-fitness](https://user-images.githubusercontent.com/137030/76610302-ff981980-6518-11ea-9fba-c0c66dca088e.png)

Observations:
- The classic algorithm fluctuates wildly without elite and circles around a fitness value that is much worse than in other cases. This is unexpected since for this kind of algorithm having an elite is theoretically not required for convergence.
- Bigger elite clearly helps in case of the classic algorithm. In case of GEWEP results vary. Sometimes it's worse but sometimes significantly better. At least having bigger elite does not seem to hurt on average.

#### 8. Mutation chance
In this experiment I increased the gene mutation chance (for all mutation types). I did not change the relative chance of each type of mutation being selected in GEWEP.

![08a-high-mutation-chance-round-fitness](https://user-images.githubusercontent.com/137030/76610303-0030b000-6519-11ea-850e-c468950ca0f7.png)
![08a-high-mutation-chance-time-fitness](https://user-images.githubusercontent.com/137030/76610304-0030b000-6519-11ea-9ae3-e0af21c381b9.png)
![08b-low-mutation-chance-round-fitness](https://user-images.githubusercontent.com/137030/76610305-00c94680-6519-11ea-9f37-417684ed71f1.png)
![08b-low-mutation-chance-time-fitness](https://user-images.githubusercontent.com/137030/76610306-00c94680-6519-11ea-8e79-ffd5bffe97b5.png)

Observations:
- High mutation chance seems consistently worse than baseline average.
- For the classic algorithm, lower chance improves results.
- For GEWEP the baseline mutation chance (3.3%) gives best results.

### Conclusions
1. GEWEP performs better than the classic genetic algorithm in almost all experiments. Its only weak spot is the sensitivity to small initial chromosome length. It converges faster, gives better final fitness and quickly reduces the chromosome length.
2. Both algorithms perform better on average than random search.
3. The use of longer chromosomes in the initial population (100-200 or more steps) improves the final fitness and makes GEWEP converge faster.
    - The downside is that the time needed to minimise the final chromosome length gets longer.
    - 12-30 steps (the current default) is definitely too short and performs badly.
4. Replacing duplicate chromosomes with random ones does not consistently improve or degrade algorithm performance.
5. All crossover operators perform similarly. Two-point crossover was slightly better in some experiments but the sample was too small to confidently say it's better than uniform crossover.
6. The classic algorithm performs badly without elite. Elite size of 50% performs better than 20%, 2% or 0%.
7. High mutation chance (10%) degrades algorithm performance. Low chance (0.1%) improves results of the classic algorithm. For GEWEP the baseline chance (3.3%) gave the best results.
8. It's not hard to get an improvement over the sequence from `Suite.cpp`. The biggest problem is consistency. Results for different random seeds vary a lot. The workaround is to run the algorithm several times and choose the best result but the algorithm should be able to deal with this problem in a single run.
    - Maybe it's actually converging too quickly. Premature convergence quickly reduces diversity of the initial population and is often a problem in genetic algorithms.

### Recommendations and possible future work
1. Build a good set of input files. The sequences produced by the algorithm already perform well enough but they must be universal to be useful. For that we need a diverse and representative set of yul code.
2. We need a code size metric better suited for the phaser. `CodeSize` assumes that certain statements are cheap because they will be optimised out. `yul-phaser` cannot make that assumption.
3. Try to make results more consistent between runs.
4. `yul-phaser` would greatly benefit from parallelisation. It's inherently well suited for that because nearly all the execution cost comes from fitness evaluation and it can be done independently for each chromosome in the population.
    - The current speed is good enough for tens of files but may become unacceptable when we start using it on hundreds or thousands of input files.
5. Another possible optimisation is a better caching strategy for chromosome prefixes.
6. Automatically stopping the algorithm once the sequence stops improving seems feasible. In GEWEP the sequence initially converges to the best fitness, then fitness stagnates but sequence length gradually decreases. Finally the sequence stops improving and running the algorithm any further is just a waste of computing power.
7. Additional postprocessing that removes superfluous steps does not seem necessary. GEWEP is already good at reducing sequence size.

### Raw data and scripts
Here's a package containing the input files, data produced from them and scripts for doing so:
[yul-phaser-experiment-report-2020-03-12.zip](https://github.com/ethereum/solidity/files/4328879/yul-phaser-experiment-report-2020-03-12.zip)

It also contains a copy of this report and plots in case you'd prefer to have them somewhere else than in a github issue.

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-601873711):

As promised, I just pushed the final PR with the code I used for experiments above. Or actually PRs since as usual, I thought it would be best to split up independent parts for ease of review. As a result, most of them are pretty small.

So here's the summary of the PRs that are still active:

Main line (including those old PRs that were not merged yet):
1. _[yul-phaser] Program cache_ #8451
2. _[yul-phaser] More output_ #8452
3. _Configurable CodeSize metric_ #8453
4. _[yul-phaser] Classic genetic algorithm_ #8515
5. _[yul-phaser] Crossover operators_ #8516
6. _[yul-phaser] Docs and defaults_ #8517

PRs directly on `develop` (these can be reviewed and merged in any order):
1. _OptimiserSuite::runSequence() overload for step abbreviations_ #8424
2. _[yul-phaser] Parsing Yul objects_ #8513
3. _[yul-phaser] --prefix option_ #8514

#### <img src="https://avatars.githubusercontent.com/u/20340?v=4" width="50">[axic](https://github.com/axic) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-623986712):

@cameel can we close this monster issue now?

It would be perhaps a good topic for a blog post to have a closure to this large body of work.

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2019-11-27 12:53](https://github.com/ethereum/solidity/issues/7806#issuecomment-624138045):

Probably. The only remaining open PR is #8453.

A blog post is already planned: https://github.com/ethereum/solidity-blog/issues/19. I've been prioritizing other tasks right now but I'm going to start working on that post soon.


-------------------------------------------------------------------------------



[Export of Github issue for [ethereum/solidity](https://github.com/ethereum/solidity). Generated on 2022.05.23 at 03:51:38.]
