# [\#4735 Issue](https://github.com/ethereum/solidity/issues/4735) `closed`: Deal with potential non-determinism in SMT checker tests.
**Labels**: `testing :hammer:`


#### <img src="https://avatars.githubusercontent.com/u/1347491?v=4" width="50">[ekpyron](https://github.com/ekpyron) opened issue at [2018-08-07 15:31](https://github.com/ethereum/solidity/issues/4735):

The results of the SMT checker tests may depend on the enabled solvers and (worse) on the available CPU power.

For the former problem, having test expectations specific to solvers should be sufficient, but this still wouldn't solve the latter problem.


#### <img src="https://avatars.githubusercontent.com/u/504195?u=ce2facd14af9fd474ebff49f0d44891f56f7500f&v=4" width="50">[leonardoalt](https://github.com/leonardoalt) commented at [2018-11-16 13:39](https://github.com/ethereum/solidity/issues/4735#issuecomment-439395564):

So far what we did is:
- The list of counterexamples is sorted by name
- The tests only take the primary error message into account. Since the counterexamples are secondary, even if different solvers give different models the tests are fine.
- All the tests that are being moved out to `.sol` files (#4645) should be fairly easy.
- Tests that use nonlinear arithmetics (e.g. division) stay in the `.cpp` tests so that `isoltest` doesn't take very long since those tests will likely smt timeout (10s at the moment).

@ekpyron @axic anything else we should do here?

#### <img src="https://avatars.githubusercontent.com/u/1347491?v=4" width="50">[ekpyron](https://github.com/ekpyron) commented at [2018-11-16 14:29](https://github.com/ethereum/solidity/issues/4735#issuecomment-439410192):

In theory we still have the problem that test results may depend on the enabled solvers and/or even on CPU power of the running system, haven't we? Maybe we should handle an SMT timeout as some kind of "soft error" in the test suite? Currently this doesn't seem to be a problem in practice, though, and I'm not sure whether there *is* a perfect solution here...

#### <img src="https://avatars.githubusercontent.com/u/504195?u=ce2facd14af9fd474ebff49f0d44891f56f7500f&v=4" width="50">[leonardoalt](https://github.com/leonardoalt) commented at [2018-11-16 14:53](https://github.com/ethereum/solidity/issues/4735#issuecomment-439417250):

Yea, I don't think there is a perfect solution, only adjustments for the practical case.
It would be nice to have all tests in `.sol` files instead of the `.cpp` tests, but then again, timeout problems. Even if we treat timeouts as error in the test suite, I wouldn't want to make `isoltest` slow.

#### <img src="https://avatars.githubusercontent.com/u/1347491?v=4" width="50">[ekpyron](https://github.com/ekpyron) commented at [2019-11-06 19:18](https://github.com/ethereum/solidity/issues/4735#issuecomment-550460000):

@leonardoalt Would you be up for thinking about a better solution for this problem in general?

What do you think about this:
For every SMT test case we know the "right" answer (i.e. sat or unsat) - if we get the opposite result, we treat it as hard error - if we get an "unknown" or "timeout", then we consider it a soft error/warning only.
Then in the end soltest and isoltest will summarize that like "150/160 SMT problems solved correctly (expected 159 for Z3 version 4.8.6)" - we could actually keep a list that maps solver version combinations to the expected number of correctly solved problems...

Do you think that'd (1) work, (2) yield a sufficient test coverage and (3) significantly reduce the issues we're having with solver versions and combinations?

#### <img src="https://avatars.githubusercontent.com/u/1347491?v=4" width="50">[ekpyron](https://github.com/ekpyron) commented at [2019-11-06 19:20](https://github.com/ethereum/solidity/issues/4735#issuecomment-550460835):

For our CI runs we could track the precise set of correctly and incorrectly solved problems and have the CI run fail, once that set changes...

#### <img src="https://avatars.githubusercontent.com/u/504195?u=ce2facd14af9fd474ebff49f0d44891f56f7500f&v=4" width="50">[leonardoalt](https://github.com/leonardoalt) commented at [2019-11-07 09:25](https://github.com/ethereum/solidity/issues/4735#issuecomment-550995830):

@ekpyron I think keeping a list of versions/solvers would be too much overhead, don't you think?

There are two different contexts the way I see.

1) Cases that are solvable by CHC but not by BMC. These require a recent Z3. Unfortunately it did happen now that 4.8.6 solves fewer cases than 4.8.5. In any case, these are hard tests, and I wouldn't mind simply updating their expectation to the newer Z3 and always require its latest version for our tests.

2) Nonlinear arithmetic cases. CVC4 manages to solve more of those than Z3, but can't solve the CHC cases.

Give 1) and 2), there isn't a single solver/version we can rely on. I like the first part of your suggestion, but I wouldn't have a list of versions. Then we could 
- update the tests using both solvers to get the strongest results
- have CI run 3 combinations (z3, cvc4, z3&cvc4), where the first two would have some warnings, and the 3rd one should have 0 warnings (like you mentioned in the last comment)
- extract the SMTChecker cpp tests

#### <img src="https://avatars.githubusercontent.com/u/1347491?v=4" width="50">[ekpyron](https://github.com/ekpyron) commented at [2019-11-07 11:15](https://github.com/ethereum/solidity/issues/4735#issuecomment-551036189):

@leonardoalt The list of versions/solvers would be optional - I just meant it to indicate to some user who runs the tests that some tests failing is fine given the solver combination and versions, but we could unconditionally state that, if SMT tests fail and not provide an "expected result" for versions/solvers, that might indeed be too much.

For our CI in particular, though, we might still keep a list of tests that may fail (resp. "warn") in a given run - that way we could even add problems that no solver can yet solve to track whether there's random improvements on those with some changes...
But yeah - fine with just requiring 0 such warnings in the "full" CI run as well.

#### <img src="https://avatars.githubusercontent.com/u/504195?u=ce2facd14af9fd474ebff49f0d44891f56f7500f&v=4" width="50">[leonardoalt](https://github.com/leonardoalt) commented at [2019-11-07 11:32](https://github.com/ethereum/solidity/issues/4735#issuecomment-551041280):

> For our CI in particular, though, we might still keep a list of tests that may fail (resp. "warn") in a given run - that way we could even add problems that no solver can yet solve to track whether there's random improvements on those with some changes...

Right, I agree with that

#### <img src="https://avatars.githubusercontent.com/u/1347491?v=4" width="50">[ekpyron](https://github.com/ekpyron) commented at [2019-11-11 17:44](https://github.com/ethereum/solidity/issues/4735#issuecomment-552543169):

To emphasize the need for this: we just took a few hours for a case in which differing AST Node IDs resulted in different results reported by Z3 - so we had different results between ``solc`` and ``isoltest``, since the latter adds ``pragma solidity >0.0.0;`` as an additional AST node to the source :-).

#### <img src="https://avatars.githubusercontent.com/u/1347491?v=4" width="50">[ekpyron](https://github.com/ekpyron) commented at [2019-11-12 10:15](https://github.com/ethereum/solidity/issues/4735#issuecomment-552827827):

Can we use resource limits instead of timeouts for Z3 and CVC4?

See for Z3: https://github.com/FStarLang/FStar/wiki/rlimits:-Machine-Independent-Resource-Limits-for-Deterministic-Execution, https://stackoverflow.com/questions/45457131/what-is-the-relation-between-options-rlimit-and-timeout, https://github.com/Z3Prover/z3/issues/216

See for CVC4: See http://cvc4.cs.stanford.edu/wiki/User_Manual - Section: Resource limits

If that works, we just need to keep the Z3 versions aligned to the current releases on all CI runs and that together with @leonardoalt's suggestion to add "strict" and "non-strict" or solver combinations to the test expectations will solve this issue.

#### <img src="https://avatars.githubusercontent.com/u/504195?u=ce2facd14af9fd474ebff49f0d44891f56f7500f&v=4" width="50">[leonardoalt](https://github.com/leonardoalt) commented at [2019-11-12 10:57](https://github.com/ethereum/solidity/issues/4735#issuecomment-552843888):

I think that would be good, but it's hard to get an idea of resources. How much would you suggest for `rlimit`?

#### <img src="https://avatars.githubusercontent.com/u/1347491?v=4" width="50">[ekpyron](https://github.com/ekpyron) commented at [2019-11-12 11:11](https://github.com/ethereum/solidity/issues/4735#issuecomment-552848762):

In the FStar blog post they say: ``You can set the rlimit using the new --z3rlimit n F* flag, where n is a natural number intuitively counting the maximum number of seconds allowed for each query when running on a mythical powerful laptop (a quad core Intel(R) Core(TM) i7-4700MQ CPU @ 2.40GHz with 16GB RAM).``
Not sure that helps too much...
Maybe we could find out the minimum value that solves all our tests and then double it or something like that?

#### <img src="https://avatars.githubusercontent.com/u/504195?u=ce2facd14af9fd474ebff49f0d44891f56f7500f&v=4" width="50">[leonardoalt](https://github.com/leonardoalt) commented at [2019-11-12 11:14](https://github.com/ethereum/solidity/issues/4735#issuecomment-552849945):

Yea, sounds good


-------------------------------------------------------------------------------



[Export of Github issue for [ethereum/solidity](https://github.com/ethereum/solidity). Generated on 2024.12.15 at 06:45:24.]
