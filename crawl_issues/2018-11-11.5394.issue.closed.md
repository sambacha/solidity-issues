# [\#5394 Issue](https://github.com/ethereum/solidity/issues/5394) `closed`: Let solc determine the minimum value of optimizer-runs which guarantees maximum optimization

#### <img src="https://avatars.githubusercontent.com/u/7003246?v=4" width="50">[barakman](https://github.com/barakman) opened issue at [2018-11-11 16:01](https://github.com/ethereum/solidity/issues/5394):

## Motivation

This feature-request follows [issue 3372](https://github.com/ethereum/solidity/issues/3372), where I was advised to set `optimizer-runs` to 5000000 - a value large enough to ensure maximum optimization.

I followed that advice, but I think that a better solution (user-perspective) would be to let `solc` determine this value, i.e., the minimum value which guarantees maximum optimization.
Moreover, ideally, `solc` would determine this value separately (and independently) for each source file, though I guess that this possibly "deserves" a separate feature-request.

In any case, this feature (if implemented) would follow a similar convention used in various IDEs, where one can configure the compiler to optimize either for speed or for memory.
Of course, there is only one "category" in our ecosystem - gas cost (which I look upon as "equivalent" to speed), but the principle should be the same IMO.

At present, in order to determine the minimum number of runs required for maximum optimization of my code, I conducted a binary-search between 200 and 5000000, until I found this number to be 1348.
During this search, I needed to compare between the output bin files, while excluding the metadata part (the 64 bytes preceding the last 2 bytes), which changes on every compilation (at least that's the case when I compile via `truffle`).
This method is far from being efficient (or convenient).

Here is a more specific reason for my request:
[Etherscan API for contract verification](https://etherscan.io/sourcecode-demo.html) does not allow for a value larger than 1000000 (of course, this issue should technically be fixed on Etherscan, not in the Solidity compiler).

Thanks.

#### <img src="https://avatars.githubusercontent.com/u/9073706?v=4" width="50">[chriseth](https://github.com/chriseth) commented at [2018-11-13 23:51](https://github.com/ethereum/solidity/issues/5394#issuecomment-438483388):

Please note that "runs" is not something like a number of iterations of the optimizer but a tradeoff parameter between runtime and deploytime gas requirements. There is no optimal value for that parameter, it always depends on the way the smart contract is about to be used. Please re-open if I misinterpreted this issue.

#### <img src="https://avatars.githubusercontent.com/u/20340?v=4" width="50">[axic](https://github.com/axic) commented at [2018-11-13 23:56](https://github.com/ethereum/solidity/issues/5394#issuecomment-438484334):

Maybe the right approach is to replace `runs` in both standard json and the CLI to reflect what it is called internally (in libevmasm at least):
```
                 /// This specifies an estimate on how often each opcode in this assembly will be executed,
                /// i.e. use a small value to optimise for size and a large value to optimise for runtime gas usage.
                size_t expectedExecutionsPerDeployment = 200;
```

#### <img src="https://avatars.githubusercontent.com/u/7003246?v=4" width="50">[barakman](https://github.com/barakman) commented at [2018-11-14 04:21](https://github.com/ethereum/solidity/issues/5394#issuecomment-438532465):

@chriseth:
From your description, as well as from @axic's, this parameter is exactly the reflection of the `optimize for size` / `optimize for speed` trade-off in "conventional systems".
It just so happens that on our system, `optimize for size` translates to 'deployment gas cost', and `optimize for speed` translates to 'runtime gas cost'.

So it sounds to me exactly like the kind of configuration that the user would prefer to leave at the hands of the compiler:
- If the user chooses `optimize deployment gas cost`, then the compiler will use `runs=0`
- If the user chooses `optimize runtime gas cost`, then the compiler will use `runs=max`, where `max` is a value calculated internally (I assume during compilation and not beforehand)

Please correct me if I've misinterpreted anything here.

#### <img src="https://avatars.githubusercontent.com/u/9073706?v=4" width="50">[chriseth](https://github.com/chriseth) commented at [2018-11-14 08:43](https://github.com/ethereum/solidity/issues/5394#issuecomment-438582575):

@barakman there is nothing to calculate. We could change the parameter to scale differently, so that you can use numbers closer to positive infinity but that's about it. Also note that this parameter is not used very much in the optimizer because almost all optimization steps improve both runtime and deploy time costs.

#### <img src="https://avatars.githubusercontent.com/u/7003246?v=4" width="50">[barakman](https://github.com/barakman) commented at [2018-11-14 09:12](https://github.com/ethereum/solidity/issues/5394#issuecomment-438590811):

@chriseth:

Thanks.

Side note: this parameter obviously has an impact in the case that I described at [issue 3372](https://github.com/ethereum/solidity/issues/3372) (or at least had an impact with the compiler version that I used at the time).


-------------------------------------------------------------------------------



[Export of Github issue for [ethereum/solidity](https://github.com/ethereum/solidity). Generated on 2024.12.15 at 06:45:24.]
