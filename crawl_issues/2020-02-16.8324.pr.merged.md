# [\#8324 PR](https://github.com/ethereum/solidity/pull/8324) `merged`: [yul-phaser] SimulationRNG

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) opened issue at [2020-02-16 00:57](https://github.com/ethereum/solidity/pull/8324):

### Description
The third pull request implementing #7806. Originally a part of #8256 which is now closed.

This pull request reworks random number generation in `yul-phaser`.
1. The loose functions from `Random.h` have been gathered into `SimulationRNG` class. They now share the same generator which can be reset with a specific seed to get reproducible sequences.
2. The seed can now be passed to the application using `--seed` option. The seed is also always printed to stdout when the application starts.
3. An extra function for generating `true`/`false` with a given probability: `bernoulliTrial()`. This is equivalent to `binomialInt()` with `numTrials = 1` but more explicit.
4. `Chromosome::randomOptimisationStep()` is now public
5. A new file for small, reusable helpers used only in tests: `test/yulPhaser/Common.h`.
6. All the added/modified code is covered by tests. Even `Common.h`.
7. Existing tests for things that depend on random values have been largely rewritten and improved. For example testing that random values are really uniform is now done by comparing the mean and squared error of a sample with theoretical expected value and variance which gives us a much stronger confidence that the results are sensible than the former test which just checked that the unlikely event of getting the same long sequence multiple times did not happen.

#### Some remarks on testing randomized stuff
I have three varieties of such tests:
- Tests that check properties that must hold no matter what the random output is. These are the best but hard to write and either complex of able to check only trivial properties.
    - Example from another PR: testing that the random algorithm does not replace the best chromosome in the population with a worse one.
- Tests that check properties that should hold with a high probability. These tests can always fail simply due to stumbling on a less likely sequence. The chance of this can be reduced by using sufficiently large number of samples or increasing tolerance but with reasonable numbers it is sometimes still high enough that we can be statistically certain that someone will encounter it over the lifetime of the project. To prevent this these tests run with a hard-coded seed. This means that the sequence is chosen once for everyone and a false-negative can be dealt with at the time of writing the tests by choosing a different seed and any future failures must be caused by regressions in the code. The downside is that false-positive (an unlikely sequence that makes the code pass even if it's bad) gets hard-coded too. But I think that a very small chance of getting such a false-positive is still more acceptable than a similarly small chance of a random failure that makes us lose confidence in CI and lose time debugging stuff that's not broken.
    - Example: checking that the random optimisation steps are chosen uniformly by comparing empirically computed parameters of a random sample with the theoretical parameters of the underlying distribution (given some small tolerance).
- Tests that depend on a specific random sequence being produced. These tests hard-code the seed and then compare the computation results with a specific hard-coded result. This makes the test very sensitive to changes in the generator and has a high chance of getting a false-positive but sometimes it's the only sensible way to keep the test simple.
    - Example: there were very few cases where I had to resort to this (none in this PR). One was the test for random mutations that add or delete genes. To test it properly I would have to write complicated helpers to diff two strings and find out where genes were inserted or deleted. Hard-coding the expected output that depends on the seed is much more fragile but also much much faster to write.

### Checklist
- [x] Code compiles correctly
- [x] All tests are passing
- [x] New tests have been created which fail without the change (if possible)
- [x] README / documentation was extended, if necessary
- [ ] Changelog entry (if change is visible to the user)
- [x] Used meaningful commit messages




-------------------------------------------------------------------------------



[Export of Github issue for [ethereum/solidity](https://github.com/ethereum/solidity). Generated on 2024.12.15 at 06:45:24.]
