# [\#11592 PR](https://github.com/ethereum/solidity/pull/11592) `merged`: Set preferred host in robots.txt

#### <img src="https://avatars.githubusercontent.com/u/20340?v=4" width="50">[axic](https://github.com/axic) opened issue at [2021-06-28 20:26](https://github.com/ethereum/solidity/pull/11592):

According to this should work: https://en.wikipedia.org/wiki/Robots_exclusion_standard#Host

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2021-06-28 20:38](https://github.com/ethereum/solidity/pull/11592#issuecomment-870024694):

I just checked `robots.txt` we serve and it does not have the content from the template: https://docs.soliditylang.org/robots.txt. It's this instead:
```robots.txt
User-agent: *

Disallow: /en/stable/ # Hidden version

Sitemap: https://docs.soliditylang.org/sitemap.xml
```

Does `scripts/docs.sh` actually run when the docs get deployed? Actually, do we deploy docs after every merge to `develop` using CI or are they only updated during release?

BTW, there's some weird catch-all redirection for `robots.txt` at RTD because even totally crazy links links like this one lead to the same file: https://docs.soliditylang.org/sfasdfasfasdf/asdf/asdf/asdfafsrobots.txt

Also, looks like Google has a validator for `robots.txt`: https://www.google.com/webmasters/tools/robots-testing-tool. Wanted to try it but then noticed that the file currently does not have the right content anyway so it's pointless until we fix it.


-------------------------------------------------------------------------------



[Export of Github issue for [ethereum/solidity](https://github.com/ethereum/solidity). Generated on 2024.12.15 at 06:45:24.]
