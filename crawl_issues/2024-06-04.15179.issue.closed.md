# [\#15179 Issue](https://github.com/ethereum/solidity/issues/15179) `closed`: Reuse optimized IR/bytecode for bytecode dependencies
**Labels**: `performance :racehorse:`, `optimizer`, `medium effort`, `high impact`, `must have`


#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) opened issue at [2024-06-04 13:43](https://github.com/ethereum/solidity/issues/15179):

## Abstract

While the IR code generator does reuse the IR that the current contract depends on (via `new`, `.runtimeCode` or `.creationCode`) it's only the unoptimized IR that is reused. There is no reuse of optimized IR, which means that we're reoptimizing dependencies (and their dependencies, recursively) from scratch every time.

## Motivation

This is likely a significant slowdown for contracts that contain a lot of bytecode dependencies. 

Benchmarking is needed to determine how much of an effect it has on compilation times in practice, but we have already established that some popular projects do have a lot of bytecode dependencies (especially when using Foundry test framework) so some attempt at code reuse here is expected to be beneficial.

## Details
As can be seen in `CompilerStack`, the compiler takes unoptimized IR of all contracts and later passes it into `IRGenerator`: https://github.com/ethereum/solidity/blob/8a97fa7a1db1ec509221ead6fea6802c684ee887/libsolidity/interface/CompilerStack.cpp#L1519-L1520

`IRGenerator` selects sources of contract's bytecode dependencies and embeds their unoptimized IR as subobjects of the contract being compiled: https://github.com/ethereum/solidity/blob/8a97fa7a1db1ec509221ead6fea6802c684ee887/libsolidity/codegen/ir/IRGenerator.cpp#L150

Then that object is optimized as a whole, without an attempt at reusing the already optimized IR of other contracts: https://github.com/ethereum/solidity/blob/8a97fa7a1db1ec509221ead6fea6802c684ee887/libsolidity/interface/CompilerStack.cpp#L1573

## Possible solutions

A quick and easy way to address this at Yul IR level would be to modify `YulStack::optimize()` to receive optimized IR of other contracts and substitute it whenever it encounters a corresponding subobject.

The downside of this, however, is that it would only address IR reuse. We'd still be doing Yul->EVM transform separately for each subobject. It also breaks encapsulation by having `YulStack` assume that the unoptimized subobject really comes from the bytecode dependency and has not been modified between code generation and optimization.

A better approach might be to defer subobject embedding and introduce a linking stage. We could have `IRGenerator` generate code only for the current contract and insert the code dependency later. The optimizer already works on each assembly separately, and knowledge about assemblies is abstracted away using builtins like `datasize()`/`dataoffset()`/`datacopy()` so this should be feasible.

The upside of this solution is that linking could be done even at the bytecode level, reusing the results of EVM->Yul transform and maybe even EVM asm optimization. The downside is that the change is more invasive and we also have to prepare compiler for dealing with unlinked (i.e. incomplete) bytecode in most of the pipeline. To avoid showing such incomplete artifacts to the user we'd also need to be prepared to do some rudimentary linking at any stage where output can be requested.

## Backwards Compatibility

This should be completely transparent to the users, unless we decide to cut corners, e.g. by outputting unlinked artifacts at intermediate stages.

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2024-09-02 12:29](https://github.com/ethereum/solidity/issues/15179#issuecomment-2324644291):

> The upside of this solution is that linking could be done even at the bytecode level, reusing the results of EVM->Yul transform and maybe even EVM asm optimization.

Last week I did some profiling to find out whether this would actually be worthwhile. Turns out that probably not. The Yul->EVM takes only ~15% of the overall compilation time while Yul optimizer takes ~70% (10-15% of which are stack optimizations). This would explain why I wasn't seeing much effect of caching the EVM artifacts in my caching experiments.

### Results

Here are the results from callgrind for IR compilation of [`chains.sol`](https://github.com/ethereum/solidity/blob/develop/test/benchmarks/chains.sol) on recent `develop`: ![chains-develop-callgrind](https://github.com/user-attachments/assets/f5498ad5-565c-4d24-a5d0-ed29ff3407be)

I think this gives a good picture of relative proportions. Numbers on real projects like Uniswap or OZ are a little different, but still consistent with the Yul optimizer being the slowest part:

| Input                                                                                                  | solc      | Yul Optimizer | Stack optimizations | Yul->EVM Transform | Profiler   |
|--------------------------------------------------------------------------------------------------------|-----------|--------------:|--------------------:|-------------------:|------------|
| [`chains.sol`](https://github.com/user-attachments/assets/f5498ad5-565c-4d24-a5d0-ed29ff3407be)        | `develop` | 78.5%         | 8.2%                | 6.9%               | callgrind  |
| [Uniswap v4](https://github.com/user-attachments/assets/5356fb40-6176-4027-b704-4c39217b54ce)          | 0.8.26    | 55%           | 0%?                 | 13.7%              | gperftools |
| [OpenZeppelin v5.0.2](https://github.com/user-attachments/assets/d2190bdb-57bd-40e5-9975-19e6fd8dcd68) | 0.8.26    | 54.9%         | 12.9%               | 15.4%              | gperftools |

Assuming that roughly:
- Yul Optimizer = `OptimizerSuite::runSequence()`
- Stack optimizations = `StackLimitEvader` + `StackCompressor`
- Yul->EVM Transform = `CompilerStack::generateEVMFromIR()`

Note also that these results are on 0.8.26, so without #15267.

EDIT: Here's how it looks on `develop`, with #15267:
| Input                                                                                                  | solc      | Yul Optimizer | Stack optimizations | Yul->EVM Transform | Profiler   |
|--------------------------------------------------------------------------------------------------------|-----------|--------------:|--------------------:|-------------------:|------------|
| [Uniswap v4](https://github.com/user-attachments/assets/2e16785d-a2bd-4e9e-ba4a-1e30dfa21eb6)          | `develop` | 39.3%         | 0%?                 | 24.7%              | gperftools |
| [OpenZeppelin v5.0.2](https://github.com/user-attachments/assets/11522bb8-8707-4bae-9427-05a2ef7d62cf) | `develop` | 50.7%         | 0%?                 | 13.9%              | gperftools |

### callgrind vs gperftools

callgrind gives pretty clean graphs, but is also unmanageably slow (it took over 24h for Uniswap and I had to kill it in the end) so I had to switch to [gperftools](https://developer.ridgerun.com/wiki/index.php/Profiling_with_GPerfTools).

For comparison, here's what I get for `chains.sol` in various runs. In particular the 50% vs 70% difference seems to be coming from the input, not from changing the profiler or from switching from `develop` to 0.8.26.

| Input                                                                                                  | solc      | Yul Optimizer | Stack optimizations | Yul->EVM Transform | Profiler   |
|--------------------------------------------------------------------------------------------------------|-----------|--------------:|--------------------:|-------------------:|------------|
| [`chains.sol`](https://github.com/user-attachments/assets/f5498ad5-565c-4d24-a5d0-ed29ff3407be)        | `develop` | 78.5%         | 8.2%               | 6.9%               | callgrind  |
| [`chains.sol`](https://github.com/user-attachments/assets/b3840cd8-e12e-483d-97e1-43682ff5b4ea)        | `develop` | 74.4%         | 13.8%               | 7.4%               | gperftools |
| [`chains.sol`](https://github.com/user-attachments/assets/3aa15ab5-0814-4561-9d27-c45328233cb5)        | 0.8.26    | 75.9%         | 9.8%                | 6.6%               | gperftools |

Curiously, the callgrind results do not show `StackLimitEvader`. I'm a bit suspicious as to the reliability of those numbers, but they are generally in the same ballpark between both tools so they're probably good enough as long as we don't require too much precision.

### Reproducing the results
#### gperftools
For completeness, here's how to run it on `chains.sol` (assuming `gperftools` is installed) in case anyone wants to play with it more:
```bash
LD_PRELOAD=/usr/lib/libprofiler.so \
CPUPROFILE="${test_name}.prof" \
    "$solc_path" chains.sol --via-ir --optimize --bin
pprof --svg "$solc_path" "${test_name}.prof" > "${test_name}.svg"
```

This method does not require building anything extra into the binary but to actually see function names on the graph you need a binary built with debug symbols, so an official release binary won't do. Also, `pprof` needs the exact same path to the binary that we used to generate the `.prof` file.

#### callgrind
```bash
valgrind --tool=callgrind \
    "$solc_path" chains.sol --via-ir --optimize --bin
kcachegrind callgrind.out.*
```

`kcachegrind` is a separate tool I used to analyze the results.

#### <img src="https://avatars.githubusercontent.com/u/1685266?v=4" width="50">[clonker](https://github.com/clonker) commented at [2024-09-03 11:12](https://github.com/ethereum/solidity/issues/15179#issuecomment-2326254446):

What optimization flag configuration did you use to benchmark?

#### <img src="https://avatars.githubusercontent.com/u/137030?v=4" width="50">[cameel](https://github.com/cameel) commented at [2024-09-03 19:55](https://github.com/ethereum/solidity/issues/15179#issuecomment-2327319937):

For Uniswap and OpenZeppelin? I used the same input that we use in [`test/benchmarks/external.sh`](https://github.com/ethereum/solidity/blob/develop/test/benchmarks/external.sh). I.e. the Standard JSON that Foundry generates for those projects when you run `forge build --optimize --offline --no-cache --via-ir`.

Uniswap:
```json
"optimizer": {"enabled": true, "runs": 44444444},
"evmVersion": "cancun",
"viaIR": true,
```

OpenZeppelin:
```json
"optimizer": {"enabled": true, "runs": 200},
"evmVersion": "cancun",
"viaIR": true,
```


-------------------------------------------------------------------------------



[Export of Github issue for [ethereum/solidity](https://github.com/ethereum/solidity). Generated on 2024.12.15 at 06:45:24.]
